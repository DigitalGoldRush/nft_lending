{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "622beb22-371b-4ed7-ac6f-96c2735e4f14",
   "metadata": {},
   "source": [
    "# Data Exploration and Cleanup Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3d672a-d9d5-464b-84f5-c05ad96fd090",
   "metadata": {},
   "source": [
    "## Initial Research\n",
    "\n",
    "---\n",
    "\n",
    "* [OpenSea API](https://docs.opensea.io/reference/api-overview) - The team could not get an API key from OpenSea, however we manually collected data from Open Sea's website for Top NFT Collections\n",
    "* [OpenSea TestNet](https://docs.opensea.io/reference/rinkeby-api-overview) - This API did not require a key, however it only interfaces with the Rinkeby testnet, and the NFT collections we were interested in analyzing only exist on the Ethereum mainnet\n",
    "* [Rarify API](https://docs.rarify.tech/reference) - The main data source for the project. Discovered their API interfaces with OpenSea's API\n",
    "* [NonFungible.com](https://nonfungible.com/market-tracker) - General NFT Market data, however the data is only provided as CSV files\n",
    "* [Nansen](https://www.nansen.ai/) - The premeire NFT data provider. Their API key required a substantial monetary subscription. However, the team used Nansen's application to manually compare NFT baskets to Nansen's NFT indexes\n",
    "* [Twitter API](https://developer.twitter.com/en/docs/twitter-api) - Provided access to perform a sentiment analysis of various NFT collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077b03e4-fc36-4417-a50c-4d2b39d3c1e9",
   "metadata": {},
   "source": [
    "## Datasets Used\n",
    "\n",
    "---\n",
    "\n",
    "Based on subscription requirements, data restrictions, and file formats we decided to only use Rarify's API to collect data for the following reasons:\n",
    "\n",
    "1. Real-time data\n",
    "2. Interfaced with OpenSea\n",
    "3. Free to use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5475230b-5105-4567-86c5-fd8f3168b8df",
   "metadata": {},
   "source": [
    "## Database Construction\n",
    "\n",
    "---\n",
    "\n",
    "The team decided to collect data from Rarify's API and store it locally in an AWS Postgres Cloud database. \n",
    "\n",
    "1. Advantages to storing the data locally:\n",
    "\n",
    "    * Data stored locally provides faster responses and ease of access\n",
    "    * Team members were not limited by API call restrictions\n",
    "    * ERD shows the relationships between collections & tokens, traits, and trade transactions on the blockchain for each collection\n",
    "    * All the data from different sources was stored in one location, allowing the same request method through the contract addresses for each NFT collection\n",
    "    \n",
    "### Entity Relationship Diagram (ERD)\n",
    "![ERD FILE](https://github.com/jgrichardson/nft_lending/blob/final_submission/images/NFT%20Lending_ERD%20v1_4.jpeg?raw=true)\n",
    "\n",
    "\n",
    "2. Rarify API provides the following data:\n",
    "    * Top 100 collections based on all time volume traded\n",
    "    * Trade transactions\n",
    "    * Top 100 tokens for each collection\n",
    "    * Traits for each collection and their rarity score\n",
    "    \n",
    "3. Extract Transform and Load Process (ETL)\n",
    "    * etl.py runs nightly to extract data from the rarify API and stores the data into the database\n",
    "    * Two Python files in the database directory (ddl.py and dml.py) create the database tables as well as the default system data used within the application\n",
    "\n",
    "\n",
    "4. SQL Queries\n",
    "    * SQL queries are used to extract data for analysis\n",
    "    \n",
    "5. CSV files\n",
    "    * Some CSV files are used as datasets in order to simplify the code for this project, it is the team's goal to finish converting all data sources to SQL based queries referencing the database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1f3adb-ee07-4821-ac9a-6a11f91ec18f",
   "metadata": {},
   "source": [
    "## Data Clean Up Process\n",
    "\n",
    "---\n",
    "\n",
    "1. The data provided by the Rarify API was initially cleaned and stored in eight SQL tables\n",
    "2. Data was filtered and cleaned from the database by individual team members once converted to Pandas DataFrames"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dev)",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
